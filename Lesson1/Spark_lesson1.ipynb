{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EAL7YbIqGFr"
      },
      "source": [
        "**Занятие первое**\n",
        "\n",
        "Начнём с простого. Многие знают, что такое map и reduce операции, но всё же для закрпеления мы их тут реализуем. Ах да, не забудем и про shuffle. Делать всё будем на упрощённой задаче с word count для ознакомления с самим подходом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DBUYlacS6nb"
      },
      "source": [
        "На самом деле мы рассмотрим всё в упрощённом виде, но это даст нам понимание, как можно через hadoop streaming, например, писать самописные map и reduce операции."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHxuTfZ1TKc9"
      },
      "source": [
        "! mapred streaming \\\n",
        "  -input /wiki/sample.jsonl \\\n",
        "  -output /word-count \\\n",
        "  -mapper \"/opt/conda/bin/python3.6 mapper.py\" \\\n",
        "  -reducer \"/opt/conda/bin/python3.6 reducer.py\" \\\n",
        "  -file mapper.py \\\n",
        "  -file reducer.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe2aSFz_Tgqv"
      },
      "source": [
        "Выше mapper.py и reducer.py это программы, которые выполняют одноимённые операции над потоком информации из jsonl файла, записывая ответ в файл word-count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hGAAKrdu5d-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPXzd-YMtqcO"
      },
      "source": [
        "Давайте загрузим файл с текстом и посмотрим на него"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKUCkYpBp9Lt"
      },
      "outputs": [],
      "source": [
        "with open(\"spark_text.txt\", \"rb\") as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "data = [text.decode() for text in data if text.decode() != \"\\r\\n\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CywPTchftnqK"
      },
      "outputs": [],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wRwGdoJ5pQs"
      },
      "outputs": [],
      "source": [
        "data[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydjOU0HLwCZq"
      },
      "source": [
        "Как бы мы сделали..\n",
        "Надо немного почистить слова, а также сделать всё в парадигме MapReduce. Понятно, что можно всё написать проще, но мы ведь хотим понять, как это работает=)\n",
        "\n",
        "Загрузим стоп слова, очистим от них текст, приведём к нижнему регистру, всем раздадим ключи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-zIUslxxtyQ"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "stop_words = set(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOXxYSKI2EfQ"
      },
      "outputs": [],
      "source": [
        "stop_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDK6W4MUewdv"
      },
      "source": [
        "пунктуацию тоже полезно бы удалить"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhrSCeUJ2MKZ"
      },
      "outputs": [],
      "source": [
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0AjYtsiv9tc"
      },
      "outputs": [],
      "source": [
        "def mapper_text(text):\n",
        "\n",
        "    clean_text = re.sub(rf\"[{string.punctuation}]\", \"\", text)\n",
        "    words = nltk.word_tokenize(clean_text)\n",
        "    words_with_value = [(word.lower(), 1) for word in words if word not in stop_words]\n",
        "    words_with_value = sorted(words_with_value, key=lambda x:x[0])\n",
        "\n",
        "    return words_with_value\n",
        "\n",
        "\n",
        "def create_chunks(shuffled_data):\n",
        "\n",
        "    result = {}\n",
        "    for idx, data in shuffled_data:\n",
        "        if idx in result:\n",
        "            result[idx].append(data)\n",
        "        else:\n",
        "            result[idx] = [data]\n",
        "\n",
        "    return list(result.items())\n",
        "\n",
        "\n",
        "def shuffle_text(mapper_result, n_nodes=5):\n",
        "\n",
        "    shuffled_data = []\n",
        "    for key, value in mapper_result:\n",
        "        shuffled_data.append((hash(key)%n_nodes, (key, value)))\n",
        "    shuffled_data = sorted(shuffled_data, key=lambda x: x[0])\n",
        "    chunks = create_chunks(shuffled_data)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# на самом деле для reduce в жизни пишут иначе.. не зря мы сортируем внутри map\n",
        "# данные по ключам. Это нужно для избавления от этапа проверки ключа и поиска\n",
        "def reduce_text(values_to_reduce):\n",
        "\n",
        "    result = {}\n",
        "    for key, value in values_to_reduce:\n",
        "        if key in result:\n",
        "            result[key] += 1\n",
        "        else:\n",
        "            result[key] = 1\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7qztZ0ijcqf"
      },
      "source": [
        "Проверим, что всё работает\n",
        "\n",
        "Сначала map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "133g98tQMT8I"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpqqPnNRhCXp"
      },
      "outputs": [],
      "source": [
        "map_stage = mapper_text(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hiOXuxSsDno"
      },
      "outputs": [],
      "source": [
        "map_stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoOq2kxGl4FM"
      },
      "source": [
        "shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLyQcJ7Xjmll"
      },
      "outputs": [],
      "source": [
        "shuffle_stage = shuffle_text(map_stage, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ig2vthBFsNTm"
      },
      "outputs": [],
      "source": [
        "shuffle_stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rqyNgzpl8q1"
      },
      "source": [
        "reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJed4iQsll9i"
      },
      "outputs": [],
      "source": [
        "reduce_text(shuffle_stage[4][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOuqRbx5srNh"
      },
      "source": [
        "Итак, осталось всё рассчитать параллельно и собрать результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NgoQwpasxwq"
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3ogNEUhtvkD"
      },
      "outputs": [],
      "source": [
        "n_nodes = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rA9awfQ4RSo"
      },
      "source": [
        "Обернем в 1 функциию для удобства map и shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TItZtKEF4Qiu"
      },
      "outputs": [],
      "source": [
        "def map_shuffle(text, n_nodes):\n",
        "\n",
        "    map_result = mapper_text(text)\n",
        "    shuffle_result = shuffle_text(map_result, n_nodes)\n",
        "\n",
        "    return shuffle_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WOywHRItFWD"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
        "    res = parallel(delayed(map_shuffle)(df, n_nodes) for df in data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIfatYoXMjPW"
      },
      "outputs": [],
      "source": [
        "len(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EgpGGu9MknD"
      },
      "outputs": [],
      "source": [
        "res[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvAYM5vA9K8N"
      },
      "source": [
        "Сделаем что-то вроде перессылки, собирая все в словари и заодно посмотрим на сколько равномерно распределлиись наши слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kTLnBO24013"
      },
      "outputs": [],
      "source": [
        "shuffle_stage = {i:[] for i in range(5)}\n",
        "for values in res:\n",
        "    values = dict(values)\n",
        "    for key in values.keys():\n",
        "        shuffle_stage[key].extend(values[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9sAjyP46kUE"
      },
      "outputs": [],
      "source": [
        "for key in shuffle_stage.keys():\n",
        "    print(f\"{key}: number of words = {len(shuffle_stage[key])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVEA-LZG9eEv"
      },
      "source": [
        "И последний этап - нужно сделать reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i95b8FbDboX"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10, batch_size=5) as parallel:\n",
        "    res = parallel(delayed(reduce_text)(shuffle_stage[key]) for key in shuffle_stage.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkGsGeKE7FeS"
      },
      "outputs": [],
      "source": [
        "len(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8on05jYEMxUp"
      },
      "outputs": [],
      "source": [
        "res[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZsgvg9oEVwt"
      },
      "source": [
        "Собираем результат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVKdO8eAD24r"
      },
      "outputs": [],
      "source": [
        "result = {}\n",
        "for partition in res:\n",
        "    for key in partition.keys():\n",
        "        if key in result:\n",
        "            result[key] += partition[key]\n",
        "        else:\n",
        "            result[key] = partition[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUTsOJf7EtW1"
      },
      "outputs": [],
      "source": [
        "sorted(result.items(), key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OViND9SFFTOd"
      },
      "source": [
        "Да, было бы проще всё сделать иным кодом и в один проход, но целью было разобрать, как всё это примерно работает под капотом на больших данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhK08F7hFjv_"
      },
      "source": [
        "**Домашнее задание**\n",
        "\n",
        "Посчитать количество рейтингов больше 4 для каждого фильма и вывести фильмы в порядке убывания количества этих оценок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPx9_0-wFlK-"
      },
      "outputs": [],
      "source": [
        "with open(\"user_ratedmovies.dat\", \"rb\") as f:\n",
        "    data = f.readlines()\n",
        "headers = data[0].decode().split(\"\\t\")[:3]\n",
        "data = [row.decode().split(\"\\t\")[:3] for row in data[1:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8yWQm0zJegy"
      },
      "outputs": [],
      "source": [
        "headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgDpQdAeRG5e"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln4GFhQZH5tM"
      },
      "outputs": [],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzkqhk9MRL8P"
      },
      "source": [
        "Пишем map, shiffle и reduce + параллелим вычисления. Лучше задавать batch_size при распараллеливании, либо даже заранее всё разбить на батчи, будет быстрее\n",
        "\n",
        "Также посмотрите на то, нет ли перекоса в данных после shuffle, можете попробовать использовать остаток от деления не простого hash, а ввести какую-то функию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1aUiwrJRK3W"
      },
      "outputs": [],
      "source": [
        "def map_rating(row):\n",
        "    pass\n",
        "\n",
        "def create_chunks(shuffled_data):\n",
        "    pass\n",
        "\n",
        "def shuffle_rating(mapper_result, n_nodes=5):\n",
        "    pass\n",
        "\n",
        "def reduce_rating(map_row):\n",
        "    pass\n",
        "\n",
        "def map_shuffle(text, n_nodes):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJdLsomDRyS0"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10) as parallel:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmKhm2eeRyVZ"
      },
      "outputs": [],
      "source": [
        "with Parallel(n_jobs=n_nodes, verbose=10) as parallel:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed0nAHrDSMcX"
      },
      "source": [
        "После reduce всё можно собрать в одном цикле, считаем, что данные переслали после на 1 машину и агрегируем"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}